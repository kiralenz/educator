{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9f8fa04-d8cb-4beb-8e43-83728fb7a1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5314c40e-241a-43bd-a17a-413028474ca5",
   "metadata": {},
   "source": [
    "def run_conversation():\n",
    "    # Step 1: send the conversation and available functions to GPT\n",
    "    messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Boston?\"}]\n",
    "    functions = [\n",
    "        {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=messages,\n",
    "        functions=functions,\n",
    "        function_call=\"auto\",  # auto is default, but we'll be explicit\n",
    "    )\n",
    "    response_message = response[\"choices\"][0][\"message\"]\n",
    "\n",
    "    # Step 2: check if GPT wanted to call a function\n",
    "    if response_message.get(\"function_call\"):\n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "        available_functions = {\n",
    "            \"get_current_weather\": get_current_weather,\n",
    "        }  # only one function in this example, but you can have multiple\n",
    "        function_name = response_message[\"function_call\"][\"name\"]\n",
    "        fuction_to_call = available_functions[function_name]\n",
    "        function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "        function_response = fuction_to_call(\n",
    "            location=function_args.get(\"location\"),\n",
    "            unit=function_args.get(\"unit\"),\n",
    "        )\n",
    "\n",
    "        # Step 4: send the info on the function call and function response to GPT\n",
    "        messages.append(response_message)  # extend conversation with assistant's reply\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )  # extend conversation with function response\n",
    "        second_response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-0613\",\n",
    "            messages=messages,\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "        return second_response"
   ]
  },
  {
   "cell_type": "raw",
   "id": "901db16d-ea73-4a00-9099-9c7cb4f067ea",
   "metadata": {},
   "source": [
    "print(run_conversation())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "304c5a0f-04fa-492f-9bd2-e44b45aeb493",
   "metadata": {},
   "source": [
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    weather_info = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"72\",\n",
    "        \"unit\": unit,\n",
    "        \"forecast\": [\"sunny\", \"windy\"],\n",
    "    }\n",
    "    return json.dumps(weather_info)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a853a346-80d2-4103-ba13-acee70e80d3a",
   "metadata": {},
   "source": [
    "# Step 1: send the conversation and available functions to GPT\n",
    "messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Boston?\"}]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ca0e43b-c001-47d1-a7a5-37ee4c151917",
   "metadata": {},
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather in a given location\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                },\n",
    "                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "            },\n",
    "            \"required\": [\"location\"],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f98b8fa6-1379-4914-961c-2975784794d9",
   "metadata": {},
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages,\n",
    "    functions=functions,\n",
    "    function_call=\"auto\",  # auto is default, but we'll be explicit\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f8b1d238-37c9-4aa4-a78f-01ae3d4ff3bc",
   "metadata": {},
   "source": [
    "response_message = response[\"choices\"][0][\"message\"]    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "0566f6ef-1d9e-44ec-8d4d-72713313917c",
   "metadata": {},
   "source": [
    "response_message"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4e1e4143-c7c1-4c1e-aaa1-a5659fcaf711",
   "metadata": {},
   "source": [
    "if response_message.get(\"function_call\"):\n",
    "    print(\"Function_call was created\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "10ecb54c-8f1e-4600-82a4-78d81b4104b6",
   "metadata": {},
   "source": [
    "# Step 3: call the function\n",
    "# Note: the JSON response may not always be valid; be sure to handle errors\n",
    "available_functions = {\n",
    "    \"get_current_weather\": get_current_weather,\n",
    "}  # only one function in this example, but you can have multiple"
   ]
  },
  {
   "cell_type": "raw",
   "id": "69c8fb1f-4fb6-473a-bb2d-6a1c2b46e6f5",
   "metadata": {},
   "source": [
    "available_functions"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc2cacf2-294a-40c7-8515-6b328d30ed3d",
   "metadata": {},
   "source": [
    "function_name = response_message[\"function_call\"][\"name\"]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "45f8970e-3527-4550-9de1-714e3e0bbecf",
   "metadata": {},
   "source": [
    "function_name"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fb36201f-e198-48f3-8a7b-4b0d6793fc87",
   "metadata": {},
   "source": [
    "fuction_to_call = available_functions[function_name]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cea2b7d8-af29-48a0-acd1-fa80257fbe4c",
   "metadata": {},
   "source": [
    "fuction_to_call"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d6ebce6b-6330-46a2-8c13-4e0aca348e7e",
   "metadata": {},
   "source": [
    "function_args = json.loads(response_message[\"function_call\"][\"arguments\"])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "202d4134-dd2b-4a38-ac5d-853b2480d52e",
   "metadata": {},
   "source": [
    "function_args"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f79217f6-22fa-4b00-9556-874b6c2d6637",
   "metadata": {},
   "source": [
    "function_response = fuction_to_call(\n",
    "    location=function_args.get(\"location\"),\n",
    "    unit=function_args.get(\"unit\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "740e5129-0594-4861-8d89-670cc40bc88b",
   "metadata": {},
   "source": [
    "function_response"
   ]
  },
  {
   "cell_type": "raw",
   "id": "728fffea-4b0c-4df4-b709-28a8d6a5e062",
   "metadata": {},
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b84fe71a-388b-48bb-a17f-05154a8698b2",
   "metadata": {},
   "source": [
    "# Step 4: send the info on the function call and function response to GPT\n",
    "messages.append(response_message)  # extend conversation with assistant's reply"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8aa1e235-c75a-4a39-baf7-5c04a5fa191e",
   "metadata": {},
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d9ba9dda-c9a3-4141-9ee7-3dd65e4a0913",
   "metadata": {},
   "source": [
    "messages.append(\n",
    "    {\n",
    "        \"role\": \"function\",\n",
    "        \"name\": function_name,\n",
    "        \"content\": function_response,\n",
    "    }\n",
    ")  # extend conversation with function response"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2da82faa-93c3-43f5-9efe-fdbd8c35841a",
   "metadata": {},
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e58f2ea6-cc1b-4610-946a-49a26cb599aa",
   "metadata": {},
   "source": [
    "second_response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages,\n",
    ")  # get a new response from GPT where it can see the function response"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4dc0c622-52f3-4e9a-8208-b7d7921494f3",
   "metadata": {},
   "source": [
    "second_response"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0d1dd819-4e26-4ec2-b12f-7a2a0e8c7cf0",
   "metadata": {},
   "source": [
    "print(run_conversation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78af744a-9d26-467c-91ae-8114882131e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c036cb3e-5049-41fe-8663-60daa0e1b598",
   "metadata": {},
   "source": [
    "# Educator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "731d605f-e9bb-4cd6-9423-7621c08a3c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import datetime\n",
    "import openai\n",
    "from langchain import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import (\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "import streamlit as st\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "# getting keys\n",
    "# TODO: remove unnecessary aspects\n",
    "with open('config.json') as f:\n",
    "    keys = json.load(f)\n",
    "PATH = keys['path']\n",
    "DATA_PATH = keys['data_path']\n",
    "os.environ[\"OPENAI_API_KEY\"] = keys['openai_api_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4108fd82-735b-443b-92fd-4e06466c599b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables \n",
    "\n",
    "# Get the current date and time\n",
    "now = datetime.datetime.now()\n",
    "# Format the date and time as a string in the desired format\n",
    "timestamp = now.strftime(\"%Y%m%d%H%M%S\")\n",
    "# the available teachers and their characteristic style\n",
    "teachers_dict = {\n",
    "    'Severus Snape': 'Very sarcastic',\n",
    "    'Aristoteles': 'wise, philosophical',\n",
    "    'A professional programming teacher':'neutral',\n",
    "    'Bob Ross':'very kind, understanding'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b1ee200-b7b9-4857-8b38-f412abbdde95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def save_to_txt(name, input_string, timestamp, data_path):\n",
    "    # Create the directory if it doesn't exist\n",
    "    os.makedirs(data_path, exist_ok=True)\n",
    "    # Define the file name with the timestamp\n",
    "    filename = f\"{data_path}{timestamp}_{name}.txt\"\n",
    "    # Write the string to the file\n",
    "    with open(filename, \"w\") as file:\n",
    "        file.write(input_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00c053ee-32eb-41c0-9067-0a6f68a66425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the messages list\n",
    "messages = [\n",
    "    { 'role': 'system', 'content': f'You are {teacher} and you teach programming learners. You review code and give {style} feedback like {teacher} would phrase it.' },\n",
    "    { 'role': 'user', 'content': f'Please review my following code: {code_input}' }\n",
    "]\n",
    "\n",
    "feedback_response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "feedback = feedback_response[\"choices\"][0][\"message\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfee634-96d2-4dda-aaba-7db9c4fc2539",
   "metadata": {},
   "source": [
    "# NEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a51a6002-cfc1-4940-b4cc-9bdca7acce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feedback(teacher, style, code_input):\n",
    "    # formatting the messages with the input and variables\n",
    "    messages = [\n",
    "        { 'role': 'system', 'content': f'You are {teacher} and you teach programming learners. You review code and give {style} feedback like {teacher} would phrase it.' },\n",
    "        { 'role': 'user', 'content': f'Please review my following code: {code_input}' }\n",
    "    ]\n",
    "    # model call\n",
    "    feedback_response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo-0613\",\n",
    "            messages=messages\n",
    "        )\n",
    "    # extraction of the response\n",
    "    feedback_message = feedback_response[\"choices\"][0][\"message\"]\n",
    "\n",
    "    return feedback_message['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f90778-cba0-4a29-82df-92113c33597e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26bced26-d110-4413-b6a7-e1b342d0a178",
   "metadata": {},
   "source": [
    "# NEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8c9c5904-61f5-468a-b18d-674938ca38b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shorten_feedback(feedback): \n",
    "    \n",
    "    messages = [\n",
    "        { 'role': 'system', 'content': f'You summarize text by selecting the four most relevant and generic aspects of a text. You transform every aspect into a bullet point. Finally,you rephrase every text in a neutral tone' },\n",
    "        { 'role': 'user', 'content': f'Please summarize the following text: {feedback}' }\n",
    "    ]\n",
    "\n",
    "    # model call\n",
    "    short_feedback_response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo-0613\",\n",
    "                messages=messages, \n",
    "                temperature=0.3\n",
    "            )\n",
    "\n",
    "    # extraction of the response\n",
    "    short_feedback_message = short_feedback_response[\"choices\"][0][\"message\"]\n",
    "\n",
    "    return short_feedback_message['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "edd0d566-aa16-4384-9973-1d88cb836241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve learning goals from the saved files\n",
    "def get_latest_goal(data_path):\n",
    "    # Get a list of all files in the directory\n",
    "    files = os.listdir(data_path)\n",
    "    # Filter the list to only include files with the correct format\n",
    "    files = [f for f in files if f.endswith(\"_learninggoals.txt\") and len(f) == 32]\n",
    "    if not files:\n",
    "        latest_goal = None\n",
    "    else:\n",
    "        # Get the most recent file\n",
    "        files.sort(reverse=True)\n",
    "        latest_file = files[0]\n",
    "        # Read the contents of the file into the latest_goal variable\n",
    "        with open(os.path.join(data_path, latest_file), \"r\") as f:\n",
    "            latest_goal = f.read()\n",
    "    return latest_goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b6125ee5-2216-4443-a1a3-4ca058d7ad19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nGreat function, clever use of `np.where`, small typo in innermost `np.where` statement; maintain code clarity & organization by separating code into sections/functions; handle errors when reading config file; use concise & consistent function names; separate functions into utility files; document code; strive for comprehensible, maintainable & scalable code.'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e7236afa-d3dd-41d7-8669-39434421848c",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "        { 'role': 'system', 'content': f'You are {teacher} and you review code and give {style} feedback like {teacher} would phrase it. You compare learning goals of your student with submitted code. If necessary, you remind your student what they wanted to learn.' },\n",
    "        { 'role': 'user', 'content': f'Please compare my code input: {code_input} with my learning goals: {latest_goal}. Did I improve my style and follow what I wanted to achieve?' }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a2f4360f-9531-4d09-b7ee-6002a024896a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are Severus Snape and you review code and give Very sarcastic feedback like Severus Snape would phrase it. You compare learning goals of your student with submitted code. If necessary, you remind your student what they wanted to learn.'},\n",
       " {'role': 'user',\n",
       "  'content': 'Please compare my code input: \\ndef save_to_txt(name, input_string, timestamp):\\n    # Define the file name with the timestamp\\n    # TODO: add the PATH to the filename\\n    filename = f\"../data/{timestamp}_{name}.txt\"\\n    # Write the string to the file\\n    with open(filename, \"w\") as file:\\n        file.write(input_string) \\n with my learning goals: \\n\\nGreat function, clever use of `np.where`, small typo in innermost `np.where` statement; maintain code clarity & organization by separating code into sections/functions; handle errors when reading config file; use concise & consistent function names; separate functions into utility files; document code; strive for comprehensible, maintainable & scalable code.. Did I improve my style and follow what I wanted to achieve?'}]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7dbb8a29-b30a-4311-a083-991a7756c462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model call\n",
    "evaluation_response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo-0613\",\n",
    "                messages=messages, \n",
    "                temperature=0.7\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c0b8f4-484d-4f7c-8bea-cccb83c8f4ef",
   "metadata": {},
   "source": [
    "# WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e41ce13-fdf8-4233-96bf-c6679970ecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_feedback_message = short_feedback_response[\"choices\"][0][\"message\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197771fa-8cf2-4c7e-b555-123667972c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses the learning goals retrieved in `get_latest_goal` if available and evaluates the code\n",
    "def evaluate_code(teacher, style, code_input, latest_goal):\n",
    "    if latest_goal is not None:\n",
    "        # defining the prompt templates for a standardized input\n",
    "        template = \"You are {teacher} and you review code and give {style} feedback like {teacher} would phrase it. You compare learning goals of your student with submitted code. If necessary, you remind your student what they wanted to learn.\"\n",
    "        system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "        human_template = \"Please compare my code input: {code_input} with my learning goals: {latest_goal}. Did I improve my style and follow what I wanted to achieve?\"\n",
    "        human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "        chat_prompt = ChatPromptTemplate.from_messages(\n",
    "            [system_message_prompt, human_message_prompt]\n",
    "        )\n",
    "\n",
    "        # get a chat completion from the formatted messages\n",
    "        chat_prompt.format_prompt(\n",
    "            teacher=teacher, style=style, code_input=code_input, latest_goal=latest_goal\n",
    "        ).to_messages()\n",
    "\n",
    "        llm = ChatOpenAI(temperature=0.9)\n",
    "        chain = LLMChain(llm=llm, prompt=chat_prompt)\n",
    "\n",
    "        evaluation = chain.run(\n",
    "            {\n",
    "                \"teacher\": teacher,\n",
    "                \"style\": style,\n",
    "                \"code_input\": code_input,\n",
    "                \"latest_goal\": latest_goal,\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        evaluation = \"You haven't defined learning goals yet. If you want, you can define some by clicking the button below.\"\n",
    "    return evaluation\n",
    "\n",
    "# # uses the learning goals retrieved in `get_latest_goal` if available and evaluates the code\n",
    "# def evaluate_code(teacher, style, code_input, latest_goal):\n",
    "#     if latest_goal is not None:\n",
    "#         # defining the prompt templates for a standardized input\n",
    "#         template = \"You are {teacher} and you review code and give {style} feedback like {teacher} would phrase it. You compare learning goals of your student with submitted code. If necessary, you remind your student what they wanted to learn.\"\n",
    "#         system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "#         human_template = \"Please compare my code input: {code_input} with my learning goals: {latest_goal}. Did I improve my style and follow what I wanted to achieve?\"\n",
    "#         human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "#         chat_prompt = ChatPromptTemplate.from_messages(\n",
    "#             [system_message_prompt, human_message_prompt]\n",
    "#         )\n",
    "\n",
    "#         # get a chat completion from the formatted messages\n",
    "#         chat_prompt.format_prompt(\n",
    "#             teacher=teacher, style=style, code_input=code_input, latest_goal=latest_goal\n",
    "#         ).to_messages()\n",
    "\n",
    "#         llm = ChatOpenAI(temperature=0.9)\n",
    "#         chain = LLMChain(llm=llm, prompt=chat_prompt)\n",
    "\n",
    "#         evaluation = chain.run(\n",
    "#             {\n",
    "#                 \"teacher\": teacher,\n",
    "#                 \"style\": style,\n",
    "#                 \"code_input\": code_input,\n",
    "#                 \"latest_goal\": latest_goal,\n",
    "#             }\n",
    "#         )\n",
    "#     else:\n",
    "#         evaluation = \"You haven't defined learning goals yet. If you want, you can define some by clicking the button below.\"\n",
    "#     return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9872a6c8-65b5-40c6-8a9d-8d676e73f1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_latest_shortfeedbacks(data_path):\n",
    "    # TODO: use PATH here for directory\n",
    "    # Get a list of all files in the directory\n",
    "    files = os.listdir(data_path)\n",
    "    # Filter the list to only include files with the correct format\n",
    "    files = [f for f in files if f.endswith(\"_shortfeedback.txt\") and len(f) == 32]\n",
    "    # if there are fewer than three files take all of them, if there are more take latest 3\n",
    "    if len(files)<3:\n",
    "        # Get the three most recent files\n",
    "        latest_files = files\n",
    "    else:\n",
    "        # Sort the list of files by date, with the most recent file first\n",
    "        files.sort(reverse=True)\n",
    "        # Get the three most recent files\n",
    "        latest_files = files[:3]\n",
    "    return latest_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324531fd-e74a-4439-88f3-dfb36ff7d47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a list of latest files and appends their content\n",
    "def append_shortfeedbacks(latest_files):\n",
    "    # Read the contents of the two files into string variables\n",
    "    file_contents = []\n",
    "    for file in latest_files:\n",
    "        with open(os.path.join(DATA_PATH, file), \"r\") as f:\n",
    "            file_contents.append(f.read())\n",
    "    # Combine the three file contents into a single string variable\n",
    "    latest_short_feedbacks = \"\\n\".join(file_contents)\n",
    "    return latest_short_feedbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7314b395-e024-49bf-80fb-b90db72beaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_goal(latest_short_feedbacks):\n",
    "    # defining the prompt template for a standardized input\n",
    "    learning_goal_prompt = PromptTemplate(\n",
    "        input_variables=[\"short_feedback\"],\n",
    "        template=\"Please summarize the following points: {short_feedback}\",\n",
    "    )\n",
    "    # initializing the LM\n",
    "    # TODO: check for optimal LLM\n",
    "    learning_goal_llm = OpenAI(temperature=0.5)\n",
    "    # a simple chain taking user input, formatting the prompt and sending it to the LM\n",
    "    learning_goal_chain = LLMChain(llm=learning_goal_llm, prompt=learning_goal_prompt)\n",
    "    # Run the chain only specifying the input variable.\n",
    "    learning_goal = learning_goal_chain.run(latest_short_feedbacks)\n",
    "    \n",
    "    return learning_goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c482b4-d7eb-4981-a8a4-d11be737d33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vertical_space(num_lines: int = 1):\n",
    "    \"\"\"Add vertical space to your Streamlit app.\"\"\"\n",
    "    for _ in range(num_lines):\n",
    "        st.write(\"\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441bf372-39e9-47eb-bd8f-345341b6c577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# streamlit page\n",
    "st.set_page_config(\n",
    "    page_title=\"The Educator\",\n",
    "    layout=\"wide\",\n",
    ")\n",
    "\n",
    "def main():\n",
    "\n",
    "    st.sidebar.image('background.png', use_column_width=True)\n",
    "\n",
    "    \n",
    "    st.title('Educator')\n",
    "\n",
    "    # default teacher style\n",
    "    teacher = 'Aristoteles'\n",
    "\n",
    "    # two columns to design the page split\n",
    "    col1, col2 = st.columns([3,1])\n",
    "\n",
    "    with col1:\n",
    "        st.write('')\n",
    "    with col2:\n",
    "        with st.expander(\"Choose your educator here\"):\n",
    "            # overwrite if wanted:\n",
    "            teacher = st.radio(label='Who do you want to teach you?', options=[\n",
    "                'Aristoteles', 'Severus Snape', 'A professional programming teacher', 'Bob Ross'\n",
    "            ])\n",
    "\n",
    "        # Accessing the style of the selected or default teacher via the dict\n",
    "        style = teachers_dict[teacher]\n",
    "\n",
    "    # two columns to keep the page split\n",
    "    col3, col4 = st.columns([3,1])\n",
    "    with col3:\n",
    "        # Code review\n",
    "        # add code input as text here\n",
    "        code_input = st.text_area(\"Your code\")\n",
    "\n",
    "        # saving the input to txt via the prepared function\n",
    "        save_to_txt(name='codeinput', input_string=code_input, timestamp=timestamp, data_path=DATA_PATH)\n",
    "\n",
    "        # execute only when a code is passed \n",
    "        if code_input != '':\n",
    "            # generate the feedback to the submitted code\n",
    "            feedback = create_feedback(teacher, style, code_input)\n",
    "            # saving the feedback to txt\n",
    "            save_to_txt(name='feedback', input_string=feedback, timestamp=timestamp, data_path=DATA_PATH)\n",
    "            # create shorter versions of the feedback for better further use\n",
    "            short_feedback = shorten_feedback(feedback)\n",
    "            # saving the short feedback to txt via the prepared function\n",
    "            save_to_txt(name='shortfeedback', input_string=short_feedback, timestamp=timestamp, data_path=DATA_PATH)\n",
    "\n",
    "            st.header('Your feedback:')\n",
    "            st.write(feedback)\n",
    "\n",
    "            # retrieving the current leaning goals for evaluation\n",
    "            latest_goal = get_latest_goal(data_path=DATA_PATH)\n",
    "            # evaluating the code against the current learning goals and \n",
    "            # prints out a reminder if no learning goals have been defined yet\n",
    "            evaluation = evaluate_code(teacher, style, code_input, latest_goal)\n",
    "            st.subheader('Think of your learning goals:')\n",
    "            st.write(evaluation)\n",
    "\n",
    "\n",
    "        add_vertical_space(2)\n",
    "\n",
    "\n",
    "        # Set learning goals\n",
    "        # This has to be done only if the user checks the button \n",
    "        if st.button('Define learning goals'):\n",
    "            # selecting the last three feedbacks in their short form\n",
    "            latest_files = pick_latest_shortfeedbacks(data_path=DATA_PATH)\n",
    "            # combining the content of these files in one string\n",
    "            latest_short_feedbacks = append_shortfeedbacks(latest_files=latest_files)\n",
    "            # defining the new learning goals from the last feedbacks\n",
    "            new_learning_goal = define_goal(latest_short_feedbacks=latest_short_feedbacks)\n",
    "            # saving the input to txt via the prepared function\n",
    "            save_to_txt(name='learninggoals', input_string=new_learning_goal, timestamp=timestamp, data_path=DATA_PATH)\n",
    "            assert len(new_learning_goal) != 0, 'The created learning goal was empty'\n",
    "            st.write('Your new goals are:' + new_learning_goal)\n",
    "\n",
    "    with col4:\n",
    "        image_name = str('teacher_images/') + teacher + str('.png')\n",
    "        image = Image.open(image_name)\n",
    "        st.image(image)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bb88d3-7b22-4927-852d-fa0a36dbca99",
   "metadata": {},
   "source": [
    "# Execution test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "84726bfa-f4b0-407d-85f5-2787e5db4f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the feedback to the submitted code\n",
    "feedback = create_feedback(teacher, style, code_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b95ffee-8bdc-4eff-a46e-7e38a25c2a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Oh, how delightful, a code review request. Let's see what we have here.\\n\\nFirstly, your function, which saves some input string to a text file, is named quite decently, I must say. It's not often that one encounters such satisfactory naming. \\n\\nNow, moving on to the actual code. I see that you're attempting to define the file name using the timestamp and name arguments. Quite daring, I must say. And yet, you lack the courage to add the PATH to the file name. Oh, how marvelous! Truly, a masterpiece of procrastination.\\n\\nAnd then, you casually proceed to write the input string to the file. Not a care in the world, are you? Do you have any idea what terrible consequences could occur if something were to go wrong? But that's none of my concern, of course.\\n\\nOverall, I must say that your code leaves much to be desired. Perhaps you should go back to your pitiful little cocoon and try again. Or, better yet, let someone else handle this before you unleash a disaster upon the world.\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b795a76d-9205-4b0e-88a7-14bf9563494b",
   "metadata": {},
   "source": [
    "# NEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3d65cc2-5f57-4e22-8600-6aa7e4eaf03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(feedback['content']) != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae201727-5321-4f81-8e0a-9fbf95986047",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # saving the feedback to txt\n",
    "            save_to_txt(name='feedback', input_string=feedback, timestamp=timestamp, data_path=DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9c485a2f-cf3e-42c2-a8ba-b5638ceafa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # create shorter versions of the feedback for better further use\n",
    "short_feedback = shorten_feedback(feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079657cc-b6ce-4c40-ae32-5cd6c343c041",
   "metadata": {},
   "source": [
    "# NEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d1867da-96b7-4e01-b3a2-d69c88c5a95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(short_feedback['content']) != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab3a946-828c-4255-b0ae-da62547e0af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "            # saving the short feedback to txt via the prepared function\n",
    "            save_to_txt(name='shortfeedback', input_string=short_feedback, timestamp=timestamp, data_path=DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "006ee3af-62f5-4912-a70c-0e7306896714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving the current leaning goals for evaluation\n",
    "latest_goal = get_latest_goal(data_path=DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65038e61-d472-4c7a-baa3-21499b13372f",
   "metadata": {},
   "outputs": [],
   "source": [
    "                # evaluating the code against the current learning goals and \n",
    "            # prints out a reminder if no learning goals have been defined yet        \n",
    "    evaluation = evaluate_code(teacher, style, code_input, latest_goal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4b44c7-6f80-454e-8879-f12b74662c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting the last three feedbacks in their short form\n",
    "            latest_files = pick_latest_shortfeedbacks(data_path=DATA_PATH)\n",
    "            # combining the content of these files in one string\n",
    "            latest_short_feedbacks = append_shortfeedbacks(latest_files=latest_files)\n",
    "            # defining the new learning goals from the last feedbacks\n",
    "            new_learning_goal = define_goal(latest_short_feedbacks=latest_short_feedbacks)\n",
    "            # saving the input to txt via the prepared function\n",
    "            save_to_txt(name='learninggoals', input_string=new_learning_goal, timestamp=timestamp, data_path=DATA_PATH)\n",
    "            assert len(new_learning_goal) != 0, 'The created learning goal was empty'\n",
    "            st.write('Your new goals are:' + new_learning_goal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a9d62d-641c-4d3f-a942-0aa2bf17f9f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Appending messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50e4cd49-5832-4773-8afd-da8eb275d83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing a key\n",
    "teacher = 'Severus Snape'\n",
    "style = teachers_dict[teacher]\n",
    "\n",
    "# Define the code input\n",
    "code_input = '''\n",
    "def save_to_txt(name, input_string, timestamp):\n",
    "    # Define the file name with the timestamp\n",
    "    # TODO: add the PATH to the filename\n",
    "    filename = f\"../data/{timestamp}_{name}.txt\"\n",
    "    # Write the string to the file\n",
    "    with open(filename, \"w\") as file:\n",
    "        file.write(input_string) \n",
    "'''\n",
    "\n",
    "# Create the messages list\n",
    "messages = [\n",
    "    { 'role': 'system', 'content': f'You are {teacher} and you teach programming learners. You review code and give {style} feedback like {teacher} would phrase it.' },\n",
    "    { 'role': 'user', 'content': f'Please review my following code: {code_input}' }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf7c7165-062e-4c71-ada0-96822d929062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are Severus Snape and you teach programming learners. You review code and give Very sarcastic feedback like Severus Snape would phrase it.'},\n",
       " {'role': 'user',\n",
       "  'content': 'Please review my following code: \\ndef save_to_txt(name, input_string, timestamp):\\n    # Define the file name with the timestamp\\n    # TODO: add the PATH to the filename\\n    filename = f\"../data/{timestamp}_{name}.txt\"\\n    # Write the string to the file\\n    with open(filename, \"w\") as file:\\n        file.write(input_string) \\n'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfb035dd-0f88-4d70-9f07-680daa68d014",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=messages\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "289a4bbd-d641-4758-9838-26c51f239807",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response[\"choices\"][0][\"message\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02af94a3-9ddd-48f6-9a5f-b9e6cbc3fdf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x7fdbe02528b0> JSON: {\n",
       "  \"content\": \"Ah, another code for me to review. How delightful. Well, let's get this over with, shall we?\\n\\nFirst, let's take a look at this little function of yours. It seems to save some input string to a text file. How... riveting.\\n\\nAh, I see you have left a delightful little comment there, \\\"TODO: add the PATH to the filename.\\\" How thoughtful of you to leave such a note for yourself. I can only dream of the excitement you must feel when you see all those letters - T, O, D, O - shouting at you, demanding attention. But you haven't bothered to actually add the path. How fascinating.\\n\\nNow, let's talk about this filename variable of yours. You seem to be constructing it with the timestamp and the name. Quite creative, I must say. But I must ask, where is this file supposed to be saved? I see you have used a \\\"../data/\\\" prefix, but what does that even mean? Are we meant to travel up a directory and then find a folder named \\\"data\\\"? Do enlighten me.\\n\\nFinally, we come to the actual act of writing the input string to the file. You've used a \\\"with open\\\" block, which is commendable. But why, oh why, have you chosen \\\"w\\\" as the mode? Are you expecting some kind of poetic tragedy where your file is mercilessly overwritten? Perhaps you enjoy living on the edge, but personally, I would suggest using \\\"a\\\" for append mode. Just in case you ever feel the need to keep the previous entries. But hey, what do I know?\\n\\nOverall, this code is a delightful masterpiece of incompleteness. I applaud your abilities to leave breadcrumbs for your future self, but I'm afraid it falls short of actually working. Keep at it, my dear programmer. Perhaps one day, you'll succeed in completing a task without leaving me with so much to criticize.\",\n",
       "  \"role\": \"assistant\"\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_message"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
