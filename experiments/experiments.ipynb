{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2743c539-a08c-4cec-abcc-80391d8cc0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import openai\n",
    "import base64\n",
    "import os\n",
    "from langchain import OpenAI\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "967b79b0-8b5e-47a4-911b-ad2dbfd7ffb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting keys\n",
    "with open('../config.json') as f:\n",
    "    keys = json.load(f)\n",
    "PATH = keys['path']\n",
    "openai_organization = keys['openai_organization']\n",
    "openai.organization = openai_organization\n",
    "openai_api_key = keys['openai_api_key']\n",
    "openai.api_key = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55f515a5-a463-4075-a574-d55e4357bd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cdcb3a-957d-4115-9a92-b5d63f73adae",
   "metadata": {},
   "source": [
    "# Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c89ceb2-6081-4861-a93c-72a3e9e37a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = pd.Timestamp.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "715123ae-9a25-4917-aae4-b1da72eb80db",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE = str(today)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefabc0f-adf3-42fb-9b28-998ebfba897f",
   "metadata": {},
   "source": [
    "# History generation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e417fd72-8724-45e6-ad33-d74e1b6fc200",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Code input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "674d4678-abee-481a-9b18-d7bfe423330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add code input as text here\n",
    "code_input = str('''\n",
    "    # Libraries\n",
    "    import streamlit as st\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import json\n",
    "    import base64\n",
    "\n",
    "    # getting variables from config.json\n",
    "    with open('config/config.json') as f:\n",
    "        keys = json.load(f)\n",
    "    PATH = keys['path']\n",
    "\n",
    "\n",
    "    # Functions\n",
    "    # better read functions from utils, but not yet working\n",
    "    def add_bg():\n",
    "        st.markdown(\n",
    "        f\"\"\"\n",
    "        <style>\n",
    "        .stApp {{\n",
    "            background-image: url(https://gist.githubusercontent.com/kiralenz/8fa216a5ab87e92944129da83d84dd5b/raw/806c89b90ee9c6eaf75f833eb9482c9cbca7dec1/bread_loaf.svg);\n",
    "            background-size: cover\n",
    "        }}\n",
    "        </style>\n",
    "        \"\"\",\n",
    "        unsafe_allow_html=True\n",
    "        )\n",
    "\n",
    "    def add_logo(height):\n",
    "        st.markdown(\n",
    "            f\"\"\"\n",
    "            <style>\n",
    "                [data-testid=\"stSidebarNav\"] {{\n",
    "                    background-image: url(https://gist.githubusercontent.com/kiralenz/16203a45856cfb596741f24f85e82fbe/raw/c9d93e3336730e77132d40df4eb8d758471bcfd8/keeprising_logo.svg);\n",
    "                    background-repeat: no-repeat;\n",
    "                    padding-top: {height - 40}px;\n",
    "                    background-position: 20px 20px;\n",
    "                }}\n",
    "            </style>\n",
    "            \"\"\",\n",
    "            unsafe_allow_html=True,\n",
    "        )\n",
    "\n",
    "    # merging historical activities (df_hist) with latest activity data (df_new) \n",
    "    # on the target or shared date column (date_column)\n",
    "    def add_latest_activity(df_hist, df_new, date_column):\n",
    "        # Fixing dtypes\n",
    "        df_hist[date_column] = df_hist[date_column].astype(str)\n",
    "        df_new[date_column] = df_new[date_column].astype(str)\n",
    "\n",
    "        # Df merging of historical feedings and latest feeding\n",
    "        df = pd.concat([df_hist, df_new], ignore_index=True)\n",
    "        # Fixing dtypes and formatting\n",
    "        df[date_column] = pd.to_datetime(df[date_column])\n",
    "        df[date_column] = df[date_column].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "        return df\n",
    "\n",
    "    # adding a column with the microbial composition based on the feeding temperature\n",
    "    def bacteria_column(df, bac_compos):\n",
    "        df['bacteria_composition'] = np.where(\n",
    "            df[\"temperature\"] <= 20,\n",
    "            bac_compos.loc[\n",
    "                bac_compos[\"temperature\"] == 20, \"dominant_microbes\"\n",
    "            ],\n",
    "            np.where(\n",
    "                ((df[\"temperature\"] > 20) & (df[\"temperature\"] <= 25)),\n",
    "                bac_compos.loc[\n",
    "                    bac_compos[\"temperature\"] == 25, \"dominant_microbes\"\n",
    "                ],\n",
    "                np.where(\n",
    "                    ((df[\"temperature\"] > 25) & (df[\"temperature\"] <= 30)),\n",
    "                    bac_compos.loc[\n",
    "                        bac_compos[\"temperature\"] == 30, \"dominant_microbes\"\n",
    "                    ],\n",
    "                    bac_compos.loc[\n",
    "                        bac_compos[\"temperature\"] == 35, \"dominant_microbes\"\n",
    "                    ],\n",
    "                ),\n",
    "            ),\n",
    "        )\n",
    "        return df\n",
    "\n",
    "    # adding two columns for growth rates to a dataframe, one is time normalized\n",
    "    def growth_rate_cols(df):\n",
    "        df['growth_rate'] = (\n",
    "            df['end_height'] / df['initial_height']\n",
    "        )\n",
    "\n",
    "        df['growth_rate_per_hour'] = (\n",
    "            df['end_height'] \n",
    "            / df['initial_height'] \n",
    "            / df['feeding_time']\n",
    "        )\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    # Loading data\n",
    "    feedings = pd.read_parquet(PATH + 'feedings.parquet')\n",
    "    bacteria_composition = pd.read_parquet(PATH + 'bacteria_composition.parquet')\n",
    "\n",
    "\n",
    "    # streamlit page\n",
    "    st.set_page_config(page_title=\"Keeprising\")\n",
    "    add_bg()  \n",
    "    add_logo(height=160)\n",
    "    st.title('How was your last feeding?') \n",
    "\n",
    "\n",
    "    # Adding new feeding data\n",
    "    # user input for feeding\n",
    "    date_today = st.date_input('Feeding date')\n",
    "    temperature_today = st.number_input('Temperature')\n",
    "    feeding_time_today = st.number_input('Feeding duration')\n",
    "    initial_height_today = st.number_input('Intial height')\n",
    "    end_height_today = st.number_input('End height')\n",
    "    bubble_size_today = st.number_input('Bubble size')\n",
    "\n",
    "    # error handling for invalid input\n",
    "    if temperature_today < 0 or feeding_time_today < 0 or initial_height_today < 0 or end_height_today < 0 or end_height_today < initial_height_today:\n",
    "        st.error('Invalid input! Please enter valid values for all feeding data. IF these had been your actual values consider immediately repeating the feeding to save your starter!')\n",
    "    else:\n",
    "        # storing latest information in a df\n",
    "        latest_feeding = pd.DataFrame(data={\n",
    "            'feeding_date':date_today, \n",
    "            'temperature':temperature_today,\n",
    "            'feeding_time':feeding_time_today,\n",
    "            'initial_height':initial_height_today,\n",
    "            'end_height':end_height_today,\n",
    "            'bubble_size':bubble_size_today\n",
    "        }, index=[0])\n",
    "\n",
    "        # merging new feeding to history of feedings\n",
    "        feedings = add_latest_activity(df_hist=feedings, df_new=latest_feeding, date_column='feeding_date')\n",
    "\n",
    "        # saving df to local file\n",
    "        feedings.to_parquet(PATH + 'feedings.parquet')\n",
    "\n",
    "        # application display of latest feedings\n",
    "        st.dataframe(feedings.tail())\n",
    "        st.write(\"Nice job! Well done!\")\n",
    "\n",
    "\n",
    "        # Data processing\n",
    "        feedings_processed = feedings.copy()\n",
    "        # Bacteria composition depending on temperature\n",
    "        feedings_processed = bacteria_column(df=feedings_processed, bac_compos=bacteria_composition)\n",
    "        # Growth rate composition\n",
    "        feedings_processed = growth_rate_cols(df=feedings_processed)\n",
    "\n",
    "\n",
    "        # Storing data\n",
    "        feedings_processed.to_parquet(PATH + 'feedings_processed.parquet')\" \n",
    "        '''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6996d30-85ae-4ecd-8519-6c928903f71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add saving to text file here"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e792d946-1485-4862-a9b3-6bfa5d726b82",
   "metadata": {},
   "source": [
    "# storing the code in a df to save as csv\n",
    "history_code = pd.DataFrame({\n",
    "    'date':today,\n",
    "    'code_input':code_input\n",
    "}, index=[0])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "693f1800-bc6f-4f80-9bd2-aab883f8b0bb",
   "metadata": {},
   "source": [
    "# formatting the df\n",
    "history_code['date'] = history_code['date'].dt.strftime(\"%Y-%m-%d\")\n",
    "history_code = history_code.set_index('date')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4617c9fa-21e0-491c-bc92-5f392a3e9295",
   "metadata": {},
   "source": [
    "history_code"
   ]
  },
  {
   "cell_type": "raw",
   "id": "00953908-34ce-41aa-b44c-4433ddeef2a9",
   "metadata": {},
   "source": [
    "# replace with PATH here\n",
    "history_code.to_csv('../data/history_code.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b290768-fe8b-444d-a153-f8254eee7eac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cf323a-1fd0-49e8-ab5a-d05aff3bc03d",
   "metadata": {},
   "source": [
    "### Test area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1273cd0-0fd6-44bb-af17-ae470c8d8a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4015124-fc91-4d8c-a54b-6b4246c9c197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Cheerful Toes.\n"
     ]
    }
   ],
   "source": [
    "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bba53493-09bb-4a97-a790-02dff44280b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What is a good name for a company that makes {product}?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7982b234-286a-44da-a6b2-6dbb45c11aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is a good name for a company that makes colorful socks?\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(product=\"colorful socks\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d83528e9-0acb-47ad-a9fd-cfa23b6105f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.9)\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What is a good name for a company that makes {product}?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4957ef08-51bf-4ca4-b048-010c57acde3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "544cba13-814e-48ef-ad35-7dbb382ad033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nVivid Socks.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"colorful socks\")\n",
    "# -> '\\n\\nSocktastic!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968b9f8a-0a80-43c7-a9ae-a6e8b70bb6b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12e547a9-f8b0-4705-a9e1-9547a19a5e6e",
   "metadata": {},
   "source": [
    "### Implementation area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e04a71e-9d7e-4aeb-8abf-3b677666934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/en/latest/modules/prompts/chat_prompt_template.html\n",
    "# defining the prompt template for a standardized input\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"code\"],\n",
    "    template=\"Please review the following code and give friendly and constructive recommendations how to improve programming style: {code}?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a070e952-218b-462e-81a7-bd01228d40c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple chain taking user input, formatting the prompt and sending it to the LM\n",
    "llm = OpenAI(temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bfc934-76f1-4b5d-ab6e-a6f8ed7468b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "607778d6-9a04-493e-ab9d-6f43e3dd4f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the model to get initial feedback\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are reviewing code and giving recommendations on programming style\"},\n",
    "        {\"role\": \"user\", \"content\": code_input},\n",
    "    ]\n",
    ")\n",
    "feedback = response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "77141ea1-4ede-4281-adc5-c1d89ccdbfd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here are some recommendations:\\n\\n1. Use meaningful variable names: The current variable names are okay, but they could be improved for better clarity and readability. For example, instead of `df_hist` and `df_new`, you could use `historical_data` and `new_data`. \\n\\n2. Modularize code: The current code is in one big chunk, and it could benefit from being broken down into smaller, more manageable functions. You could have a separate file for functions that can be reused across applications. \\n\\n3. Use docstrings: It would be helpful to have docstrings that describe what each function does, what arguments are expected, and what the function returns. This would make it easier for someone else to understand and use the code. \\n\\n4. Avoid hardcoding: It is good to load variables such as file paths or configuration parameters from external files like `config.json`, but there are still some hardcoded values such as the background image and logo URLs. It would be better to store these values in some external resource so that they can be easily updated if needed.\\n\\n5. Add error handling: Error handling is currently only implemented for invalid input, but it would be good to anticipate other types of errors that might occur, such as file not found errors, and handle them gracefully. \\n\\n6. Use consistent formatting: The code has inconsistent formatting and indentation, and this makes it harder to read and understand. You could use a tool like `black` to automatically format the code before committing it. \\n\\n7. Organize imports: It's a good practice to group imports in a specific order. For instance, you could first import standard library modules, then third-party packages, and finally, project-specific modules. You could also sort the imports alphabetically within each group. Doing this makes the code look more organized and easier to navigate.\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e5acb5f7-3a68-44af-b45b-22de139b92a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_feedback = pd.DataFrame({\n",
    "    'date':today,\n",
    "    'feedback':feedback\n",
    "}, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "abbd8261-1b36-4b27-944a-6a932ec1a2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatting the df\n",
    "history_feedback['date'] = history_feedback['date'].dt.strftime(\"%Y-%m-%d\")\n",
    "history_feedback = history_feedback.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b025eb74-a9c4-4981-a812-a1f7bcde93bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace with PATH here\n",
    "history_feedback.to_csv('../data/history_feedback.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a840f364-94f1-4f4f-8537-0e0be5579404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e5619e8-5410-48cc-a2f1-9f6276e3134b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Shorten review for learning target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a1319e4b-d87a-4f6f-8026-cf7e0f3ae497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the model to create a short form of the feedback\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Summarise the points of this feedback and give back only the summarised points\"},\n",
    "        {\"role\": \"user\", \"content\": feedback},\n",
    "    ]\n",
    ")\n",
    "short_feedback = response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3d1c87ca-3e30-41d6-ae1c-e19d9dd605b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The feedback suggests that the code can be improved by: \\n1. using meaningful variable names, \\n2. modularizing the code, \\n3. using docstrings to describe functions, \\n4. avoiding hardcoding values, \\n5. adding error handling, \\n6. using consistent formatting, and \\n7. organizing imports.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae57cdea-bee8-487f-aeb4-448ff2418c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO or TOCHECK: maybe directly storing in a json with a date as name part "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6345bbe4-00df-4889-92ae-1afdce2b8c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_short_feedback = pd.DataFrame({\n",
    "    'date':today,\n",
    "    'short_feedback':short_feedback\n",
    "}, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a1523bfe-f27f-43fc-9319-81aa3645e20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatting the df\n",
    "history_short_feedback['date'] = history_short_feedback['date'].dt.strftime(\"%Y-%m-%d\")\n",
    "history_short_feedback = history_short_feedback.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b39f80e2-9ddb-4c06-b7be-7f8c7661569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace with PATH here\n",
    "history_short_feedback.to_csv('../data/history_short_feedback.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb9f40b-10a9-435c-994b-b47ddad995c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea2bf6f9-7db8-48f3-a55d-148e686b2b5a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Adding new code reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4819dfb1-aaac-4f6f-8405-8ff1a39cfc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add code input as text here\n",
    "# code_input = str('''\n",
    "# '''\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a87bd082-e0e8-4dec-8a0b-97982a89cfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d56de725-52b7-49f6-a7d1-1a8ec26a6f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# today = pd.Timestamp.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44477119-1c45-4d57-ae76-7f3bd5eb3d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace with PATH here\n",
    "# history_code = pd.read_csv('../data/history_code.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58c92549-0469-45fd-abc0-bdba2f1a0fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the code in a df to save as csv\n",
    "# latest_code = pd.DataFrame({\n",
    "#     'date':today,\n",
    "#     'code_input':code_input\n",
    "# }, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f988dc31-f677-4a00-95a5-ddd0e93aa6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating the history file\n",
    "# history_code = pd.concat([history_code, latest_code], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ca215a0-e8bf-428e-a842-f31e6da69add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwriting the history file with the latest version\n",
    "# history_code.to_csv('../data/history_code.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8693c0a-22c6-4999-8202-68754010119d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the model to get initial feedback\n",
    "# response = openai.ChatCompletion.create(\n",
    "#   model=\"gpt-3.5-turbo\",\n",
    "#   messages=[\n",
    "#         {\"role\": \"system\", \"content\": \"You are reviewing code and giving recommendations on programming style\"},\n",
    "#         {\"role\": \"user\", \"content\": code_input},\n",
    "#     ]\n",
    "# )\n",
    "# feedback = response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98f282a6-c5b4-4183-9fa4-c1ca32acd693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17c05084-0ff1-4c99-a7e7-814150fb81d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace with PATH here\n",
    "# history_feedback = pd.read_csv('../data/history_feedback.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5d2a097-b7ac-458a-a95c-fda5a8b4876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latest_feedback = pd.DataFrame({\n",
    "#     'date':today,\n",
    "#     'code_input':feedback\n",
    "# }, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5e803b8-5757-4749-a029-5ab368642f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating the history file\n",
    "# history_feedback = pd.concat([history_feedback, latest_feedback], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f375afce-d40c-4023-b6eb-090da245e1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwriting the file\n",
    "# history_feedback.to_csv('../data/history_feedback.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6affaef-0216-47b9-b47b-af85334e5d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76330750-b652-4bb5-9b0e-01eebadaaf14",
   "metadata": {},
   "source": [
    "# Learning goals "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b536255f-8a9e-4a33-88c3-9d0180ee0c89",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Set learning goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9cbd79ef-9256-4ba2-a5bc-d298ea5e8233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This has to be done before the latest request is added OR only if the user checks a button like \"generate learning targets\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a8cd72-57e2-445c-92ec-95c7e660f528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe select only the last X feedbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "65ea857a-3e1f-4966-8e16-e2393d716756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace with PATH here\n",
    "# read all short feedbacks\n",
    "history_short_feedback = pd.read_csv(\n",
    "    '../data/history_short_feedback.csv', \n",
    "    # index_col='date'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6dc1a787-3562-43b5-86af-4032b5f4571d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>short_feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-21</td>\n",
       "      <td>The feedback suggests that the code can be imp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                     short_feedback\n",
       "0  2023-04-21  The feedback suggests that the code can be imp..."
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_short_feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "48dd6c60-bacd-4221-8db2-bbdfec00b0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_feedb_json = history_short_feedback['short_feedback'].to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "afbe2425-f2b7-4e7c-a9f3-6ea781438b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"0\":\"The feedback suggests that the code can be improved by: \\\\n1. using meaningful variable names, \\\\n2. modularizing the code, \\\\n3. using docstrings to describe functions, \\\\n4. avoiding hardcoding values, \\\\n5. adding error handling, \\\\n6. using consistent formatting, and \\\\n7. organizing imports.\"}'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_feedb_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def47acc-b591-4c9b-8f2b-e966c4d634f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe add a rule like \"put special weight on recurring aspects\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "51ddb424-6345-4ad9-8955-e3467e974c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the model to get initial feedback\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Summarize the feedback and create up to 4 short learning targets. A learning target should be an aspect of coding the user can focus on and try to improve when coding\"},\n",
    "        {\"role\": \"user\", \"content\": short_feedb_json},\n",
    "    ]\n",
    ")\n",
    "learning_target = response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5cf7b84b-fdcd-4f88-9439-1d7f21885090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Learning targets:\\n1. Improve variable naming by using descriptive and meaningful names.\\n2. Create modular code by breaking down complex functions into smaller, reusable modules.\\n3. Use docstrings to clearly and concisely describe the purpose of functions.\\n4. Avoid hardcoding values and use variables/constants whenever possible.'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "647f8d6b-07b1-46c3-ab18-4bf464b8d898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the string variable to a JSON file\n",
    "with open('../data/learning_target.json', 'w') as f:\n",
    "    json.dump(learning_target, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59846ced-0877-484d-96ca-7f971d89604c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add option to generate new learning targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecbbaf3-c1e0-44de-a738-676f67687019",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compare learning goals and latest submitted code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c07a2994-44b1-4cde-a6b5-2c30a201880d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the JSON file\n",
    "with open('../data/learning_target.json', 'r') as f:\n",
    "    learning_target = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8adc820a-59ed-49cc-b56e-14f0cec8ca46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Learning targets:\\n1. Improve variable naming by using descriptive and meaningful names.\\n2. Create modular code by breaking down complex functions into smaller, reusable modules.\\n3. Use docstrings to clearly and concisely describe the purpose of functions.\\n4. Avoid hardcoding values and use variables/constants whenever possible.'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cde68068-ec49-4ac3-af52-8ee52c963c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here are some recommendations:\\n\\n1. Use meaningful variable names: The current variable names are okay, but they could be improved for better clarity and readability. For example, instead of `df_hist` and `df_new`, you could use `historical_data` and `new_data`. \\n\\n2. Modularize code: The current code is in one big chunk, and it could benefit from being broken down into smaller, more manageable functions. You could have a separate file for functions that can be reused across applications. \\n\\n3. Use docstrings: It would be helpful to have docstrings that describe what each function does, what arguments are expected, and what the function returns. This would make it easier for someone else to understand and use the code. \\n\\n4. Avoid hardcoding: It is good to load variables such as file paths or configuration parameters from external files like `config.json`, but there are still some hardcoded values such as the background image and logo URLs. It would be better to store these values in some external resource so that they can be easily updated if needed.\\n\\n5. Add error handling: Error handling is currently only implemented for invalid input, but it would be good to anticipate other types of errors that might occur, such as file not found errors, and handle them gracefully. \\n\\n6. Use consistent formatting: The code has inconsistent formatting and indentation, and this makes it harder to read and understand. You could use a tool like `black` to automatically format the code before committing it. \\n\\n7. Organize imports: It's a good practice to group imports in a specific order. For instance, you could first import standard library modules, then third-party packages, and finally, project-specific modules. You could also sort the imports alphabetically within each group. Doing this makes the code look more organized and easier to navigate.\""
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc888f4-256a-432c-b5c2-62f43ecf7f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Improve system prompt!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8e0d14-8309-4e9e-8956-e7fe5aced675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the model to get initial feedback\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Compare the learning targets and the feedback. If there is a strong overlap between the latest feedback and the learning targets, the user didn't pay attention to the targets. If that is the case, give him a friendly reminder to pay attention to the learning targets.\"},\n",
    "        {\"role\": \"user\", \"content\": learning_target},\n",
    "        {\"role\": \"user\", \"content\": feedback}\n",
    "    ]\n",
    ")\n",
    "reminder = response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1830db12-e714-4bc5-8421-6475e65916f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thanks for the recommendations. It seems like you have a good understanding of the learning targets. However, I noticed that your feedback mostly overlaps with learning targets one, two, and three. Remember to pay attention to all the learning targets when providing feedback. It is important to cover all the areas in which the user needs to improve.'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reminder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
