{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9f8fa04-d8cb-4beb-8e43-83728fb7a1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2743c539-a08c-4cec-abcc-80391d8cc0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import openai\n",
    "import base64\n",
    "import os\n",
    "from langchain import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "967b79b0-8b5e-47a4-911b-ad2dbfd7ffb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting keys\n",
    "# TODO: remove unnecessary aspects\n",
    "with open('../config.json') as f:\n",
    "    keys = json.load(f)\n",
    "PATH = keys['path']\n",
    "openai_organization = keys['openai_organization']\n",
    "openai.organization = openai_organization\n",
    "openai_api_key = keys['openai_api_key']\n",
    "openai.api_key = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55f515a5-a463-4075-a574-d55e4357bd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cdcb3a-957d-4115-9a92-b5d63f73adae",
   "metadata": {},
   "source": [
    "# Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c89ceb2-6081-4861-a93c-72a3e9e37a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = pd.Timestamp.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "715123ae-9a25-4917-aae4-b1da72eb80db",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE = str(today)[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefabc0f-adf3-42fb-9b28-998ebfba897f",
   "metadata": {},
   "source": [
    "# History generation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e417fd72-8724-45e6-ad33-d74e1b6fc200",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Code input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "674d4678-abee-481a-9b18-d7bfe423330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add code input as text here\n",
    "code_input = str('''\n",
    "    # Libraries\n",
    "    import streamlit as st\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import json\n",
    "    import base64\n",
    "\n",
    "    # getting variables from config.json\n",
    "    with open('config/config.json') as f:\n",
    "        keys = json.load(f)\n",
    "    PATH = keys['path']\n",
    "\n",
    "\n",
    "    # Functions\n",
    "    # better read functions from utils, but not yet working\n",
    "    def add_bg():\n",
    "        st.markdown(\n",
    "        f\"\"\"\n",
    "        <style>\n",
    "        .stApp {{\n",
    "            background-image: url(https://gist.githubusercontent.com/kiralenz/8fa216a5ab87e92944129da83d84dd5b/raw/806c89b90ee9c6eaf75f833eb9482c9cbca7dec1/bread_loaf.svg);\n",
    "            background-size: cover\n",
    "        }}\n",
    "        </style>\n",
    "        \"\"\",\n",
    "        unsafe_allow_html=True\n",
    "        )\n",
    "\n",
    "    def add_logo(height):\n",
    "        st.markdown(\n",
    "            f\"\"\"\n",
    "            <style>\n",
    "                [data-testid=\"stSidebarNav\"] {{\n",
    "                    background-image: url(https://gist.githubusercontent.com/kiralenz/16203a45856cfb596741f24f85e82fbe/raw/c9d93e3336730e77132d40df4eb8d758471bcfd8/keeprising_logo.svg);\n",
    "                    background-repeat: no-repeat;\n",
    "                    padding-top: {height - 40}px;\n",
    "                    background-position: 20px 20px;\n",
    "                }}\n",
    "            </style>\n",
    "            \"\"\",\n",
    "            unsafe_allow_html=True,\n",
    "        )\n",
    "\n",
    "    # merging historical activities (df_hist) with latest activity data (df_new) \n",
    "    # on the target or shared date column (date_column)\n",
    "    def add_latest_activity(df_hist, df_new, date_column):\n",
    "        # Fixing dtypes\n",
    "        df_hist[date_column] = df_hist[date_column].astype(str)\n",
    "        df_new[date_column] = df_new[date_column].astype(str)\n",
    "\n",
    "        # Df merging of historical feedings and latest feeding\n",
    "        df = pd.concat([df_hist, df_new], ignore_index=True)\n",
    "        # Fixing dtypes and formatting\n",
    "        df[date_column] = pd.to_datetime(df[date_column])\n",
    "        df[date_column] = df[date_column].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "        return df\n",
    "\n",
    "    # adding a column with the microbial composition based on the feeding temperature\n",
    "    def bacteria_column(df, bac_compos):\n",
    "        df['bacteria_composition'] = np.where(\n",
    "            df[\"temperature\"] <= 20,\n",
    "            bac_compos.loc[\n",
    "                bac_compos[\"temperature\"] == 20, \"dominant_microbes\"\n",
    "            ],\n",
    "            np.where(\n",
    "                ((df[\"temperature\"] > 20) & (df[\"temperature\"] <= 25)),\n",
    "                bac_compos.loc[\n",
    "                    bac_compos[\"temperature\"] == 25, \"dominant_microbes\"\n",
    "                ],\n",
    "                np.where(\n",
    "                    ((df[\"temperature\"] > 25) & (df[\"temperature\"] <= 30)),\n",
    "                    bac_compos.loc[\n",
    "                        bac_compos[\"temperature\"] == 30, \"dominant_microbes\"\n",
    "                    ],\n",
    "                    bac_compos.loc[\n",
    "                        bac_compos[\"temperature\"] == 35, \"dominant_microbes\"\n",
    "                    ],\n",
    "                ),\n",
    "            ),\n",
    "        )\n",
    "        return df\n",
    "\n",
    "    # adding two columns for growth rates to a dataframe, one is time normalized\n",
    "    def growth_rate_cols(df):\n",
    "        df['growth_rate'] = (\n",
    "            df['end_height'] / df['initial_height']\n",
    "        )\n",
    "\n",
    "        df['growth_rate_per_hour'] = (\n",
    "            df['end_height'] \n",
    "            / df['initial_height'] \n",
    "            / df['feeding_time']\n",
    "        )\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    # Loading data\n",
    "    feedings = pd.read_parquet(PATH + 'feedings.parquet')\n",
    "    bacteria_composition = pd.read_parquet(PATH + 'bacteria_composition.parquet')\n",
    "\n",
    "\n",
    "    # streamlit page\n",
    "    st.set_page_config(page_title=\"Keeprising\")\n",
    "    add_bg()  \n",
    "    add_logo(height=160)\n",
    "    st.title('How was your last feeding?') \n",
    "\n",
    "\n",
    "    # Adding new feeding data\n",
    "    # user input for feeding\n",
    "    date_today = st.date_input('Feeding date')\n",
    "    temperature_today = st.number_input('Temperature')\n",
    "    feeding_time_today = st.number_input('Feeding duration')\n",
    "    initial_height_today = st.number_input('Intial height')\n",
    "    end_height_today = st.number_input('End height')\n",
    "    bubble_size_today = st.number_input('Bubble size')\n",
    "\n",
    "    # error handling for invalid input\n",
    "    if temperature_today < 0 or feeding_time_today < 0 or initial_height_today < 0 or end_height_today < 0 or end_height_today < initial_height_today:\n",
    "        st.error('Invalid input! Please enter valid values for all feeding data. IF these had been your actual values consider immediately repeating the feeding to save your starter!')\n",
    "    else:\n",
    "        # storing latest information in a df\n",
    "        latest_feeding = pd.DataFrame(data={\n",
    "            'feeding_date':date_today, \n",
    "            'temperature':temperature_today,\n",
    "            'feeding_time':feeding_time_today,\n",
    "            'initial_height':initial_height_today,\n",
    "            'end_height':end_height_today,\n",
    "            'bubble_size':bubble_size_today\n",
    "        }, index=[0])\n",
    "\n",
    "        # merging new feeding to history of feedings\n",
    "        feedings = add_latest_activity(df_hist=feedings, df_new=latest_feeding, date_column='feeding_date')\n",
    "\n",
    "        # saving df to local file\n",
    "        feedings.to_parquet(PATH + 'feedings.parquet')\n",
    "\n",
    "        # application display of latest feedings\n",
    "        st.dataframe(feedings.tail())\n",
    "        st.write(\"Nice job! Well done!\")\n",
    "\n",
    "\n",
    "        # Data processing\n",
    "        feedings_processed = feedings.copy()\n",
    "        # Bacteria composition depending on temperature\n",
    "        feedings_processed = bacteria_column(df=feedings_processed, bac_compos=bacteria_composition)\n",
    "        # Growth rate composition\n",
    "        feedings_processed = growth_rate_cols(df=feedings_processed)\n",
    "\n",
    "\n",
    "        # Storing data\n",
    "        feedings_processed.to_parquet(PATH + 'feedings_processed.parquet')\" \n",
    "        '''\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977c1134-4098-4497-a866-c6e587603b70",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### add saving to text file here"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e792d946-1485-4862-a9b3-6bfa5d726b82",
   "metadata": {},
   "source": [
    "# storing the code in a df to save as csv\n",
    "history_code = pd.DataFrame({\n",
    "    'date':today,\n",
    "    'code_input':code_input\n",
    "}, index=[0])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "693f1800-bc6f-4f80-9bd2-aab883f8b0bb",
   "metadata": {},
   "source": [
    "# formatting the df\n",
    "history_code['date'] = history_code['date'].dt.strftime(\"%Y-%m-%d\")\n",
    "history_code = history_code.set_index('date')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4617c9fa-21e0-491c-bc92-5f392a3e9295",
   "metadata": {},
   "source": [
    "history_code"
   ]
  },
  {
   "cell_type": "raw",
   "id": "00953908-34ce-41aa-b44c-4433ddeef2a9",
   "metadata": {},
   "source": [
    "# replace with PATH here\n",
    "history_code.to_csv('../data/history_code.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b290768-fe8b-444d-a153-f8254eee7eac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cf323a-1fd0-49e8-ab5a-d05aff3bc03d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Test area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1273cd0-0fd6-44bb-af17-ae470c8d8a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4015124-fc91-4d8c-a54b-6b4246c9c197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "BrightToe Socks\n"
     ]
    }
   ],
   "source": [
    "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
    "print(llm(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bba53493-09bb-4a97-a790-02dff44280b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What is a good name for a company that makes {product}?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7982b234-286a-44da-a6b2-6dbb45c11aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is a good name for a company that makes colorful socks?\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(product=\"colorful socks\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d83528e9-0acb-47ad-a9fd-cfa23b6105f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.9)\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What is a good name for a company that makes {product}?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4957ef08-51bf-4ca4-b048-010c57acde3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "544cba13-814e-48ef-ad35-7dbb382ad033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nHappyToes Socks.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"colorful socks\")\n",
    "# -> '\\n\\nSocktastic!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968b9f8a-0a80-43c7-a9ae-a6e8b70bb6b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12e547a9-f8b0-4705-a9e1-9547a19a5e6e",
   "metadata": {},
   "source": [
    "### Langchain implementation area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e04a71e-9d7e-4aeb-8abf-3b677666934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://python.langchain.com/en/latest/modules/prompts/chat_prompt_template.html\n",
    "# defining the prompt template for a standardized input\n",
    "# TODO: refine prompt\n",
    "feedback_prompt = PromptTemplate(\n",
    "    input_variables=[\"code\"],\n",
    "    template=\"Please review the following code and give five recommendations with explanations how to improve the programming: {code}?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a070e952-218b-462e-81a7-bd01228d40c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the LM\n",
    "# TO EXPLORE: adjust temperature\n",
    "# TO EXPLORE: test other LMs\n",
    "feedback_llm = OpenAI(temperature=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02bfc934-76f1-4b5d-ab6e-a6f8ed7468b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple chain taking user input, formatting the prompt and sending it to the LM\n",
    "feedback_chain = LLMChain(llm=feedback_llm, prompt=feedback_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4febd6b1-59f4-4177-9666-66555cf27f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the chain only specifying the input variable.\n",
    "feedback = feedback_chain.run(code_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74644da9-bab4-4f9d-a862-a2de762bbf5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n1. Move the code that is not related to the Streamlit application (e.g. functions, loading data, data processing) to a separate file. This will make the code easier to read and maintain. \\n\\n2. Move the code for styling the Streamlit application (e.g. add_bg(), add_logo()) to a separate file. This will make the code easier to read and maintain. \\n\\n3. Use meaningful variable names to improve readability. For example, instead of PATH, use file_path. \\n\\n4. Use more descriptive names for functions. For example, instead of add_latest_activity, use merge_historical_and_latest_activity. \\n\\n5. Add comments to explain the purpose of each function and the code blocks. This will make the code easier to understand.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91369bdb-5a90-4852-a7a4-38d674b37688",
   "metadata": {},
   "source": [
    "#### TODO: save feedback to text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffc95c2-d3f5-47a6-b965-7423f640acfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a298c43a-bb30-4a45-bcf8-8bfdab65cea3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Direct API call area OLD"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3df0c232-de13-4962-a786-940949a2ad79",
   "metadata": {},
   "source": [
    "# calling the model to get initial feedback\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are reviewing code and giving recommendations on programming style\"},\n",
    "        {\"role\": \"user\", \"content\": code_input},\n",
    "    ]\n",
    ")\n",
    "feedback = response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c4e3b992-40c9-4d84-83f9-c74372f4641c",
   "metadata": {},
   "source": [
    "feedback"
   ]
  },
  {
   "cell_type": "raw",
   "id": "955b2dcd-acb3-4920-9f4b-c77cc0a17df1",
   "metadata": {},
   "source": [
    "history_feedback = pd.DataFrame({\n",
    "    'date':today,\n",
    "    'feedback':feedback\n",
    "}, index=[0])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5184ea8b-0ec4-4c15-9538-73757f90e58c",
   "metadata": {},
   "source": [
    "# formatting the df\n",
    "history_feedback['date'] = history_feedback['date'].dt.strftime(\"%Y-%m-%d\")\n",
    "history_feedback = history_feedback.set_index('date')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b8d61441-4ba1-4139-8fda-cf214ee6f14b",
   "metadata": {},
   "source": [
    "# replace with PATH here\n",
    "history_feedback.to_csv('../data/history_feedback.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a840f364-94f1-4f4f-8537-0e0be5579404",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e5619e8-5410-48cc-a2f1-9f6276e3134b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Shorten review for learning target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8085458f-4271-47d1-b388-2f6269216934",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Langchain implementation area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8ebed97-886d-42cb-8f2d-7690ebdf87dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the prompt template for a standardized input\n",
    "short_feedback_prompt = PromptTemplate(\n",
    "    input_variables=[\"feedback\"],\n",
    "    template=\"Please shorten the aspects of the following feeback: {feedback}?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4ac53e1-aaf8-425e-b1d1-9381964e75c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the LM\n",
    "short_feedback_llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c5c31d7-1c43-4aca-ad0e-5d9a9c6f28bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple chain taking user input, formatting the prompt and sending it to the LM\n",
    "short_feedback_chain = LLMChain(llm=short_feedback_llm, prompt=short_feedback_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76a238ec-17ec-451a-985d-9c4eba43dce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the chain only specifying the input variable.\n",
    "short_feedback = short_feedback_chain.run(feedback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ac2da05-970e-4456-bd35-b57c9850e9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n1. Move non-Streamlit code to separate file.\\n2. Move Streamlit styling code to separate file.\\n3. Use meaningful variable names.\\n4. Use descriptive function names.\\n5. Add comments to explain code.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c3a1fb-54ba-491d-a234-f45146da546b",
   "metadata": {},
   "source": [
    "#### TODO: save feedback to text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1115ac1-9b04-4107-9d4c-e6f4e032f606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13ec4f1a-95db-48cd-a206-54f5b595ce91",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Direct API call area OLD"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c28f14c0-6813-4e2b-98b6-78658f4b9455",
   "metadata": {},
   "source": [
    "# calling the model to create a short form of the feedback\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Summarise the points of this feedback and give back only the summarised points\"},\n",
    "        {\"role\": \"user\", \"content\": feedback},\n",
    "    ]\n",
    ")\n",
    "short_feedback = response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eaf506ac-e1e7-49b3-9ad1-3c49c64acbaf",
   "metadata": {},
   "source": [
    "short_feedback"
   ]
  },
  {
   "cell_type": "raw",
   "id": "33f5ff5f-7759-43c3-a42c-eb687d265c17",
   "metadata": {},
   "source": [
    "# TODO or TOCHECK: maybe directly storing in a json with a date as name part "
   ]
  },
  {
   "cell_type": "raw",
   "id": "e41badef-5fca-406f-a805-c62387f9a9a9",
   "metadata": {},
   "source": [
    "history_short_feedback = pd.DataFrame({\n",
    "    'date':today,\n",
    "    'short_feedback':short_feedback\n",
    "}, index=[0])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "20880892-da52-4f3f-9d31-41d4337cfb94",
   "metadata": {},
   "source": [
    "# formatting the df\n",
    "history_short_feedback['date'] = history_short_feedback['date'].dt.strftime(\"%Y-%m-%d\")\n",
    "history_short_feedback = history_short_feedback.set_index('date')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "baa93eb3-b512-408b-8193-76a66b5496e3",
   "metadata": {},
   "source": [
    "# replace with PATH here\n",
    "history_short_feedback.to_csv('../data/history_short_feedback.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb9f40b-10a9-435c-994b-b47ddad995c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea2bf6f9-7db8-48f3-a55d-148e686b2b5a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Adding new code reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4819dfb1-aaac-4f6f-8405-8ff1a39cfc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add code input as text here\n",
    "# code_input = str('''\n",
    "# '''\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a87bd082-e0e8-4dec-8a0b-97982a89cfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d56de725-52b7-49f6-a7d1-1a8ec26a6f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# today = pd.Timestamp.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44477119-1c45-4d57-ae76-7f3bd5eb3d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace with PATH here\n",
    "# history_code = pd.read_csv('../data/history_code.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58c92549-0469-45fd-abc0-bdba2f1a0fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the code in a df to save as csv\n",
    "# latest_code = pd.DataFrame({\n",
    "#     'date':today,\n",
    "#     'code_input':code_input\n",
    "# }, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f988dc31-f677-4a00-95a5-ddd0e93aa6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating the history file\n",
    "# history_code = pd.concat([history_code, latest_code], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ca215a0-e8bf-428e-a842-f31e6da69add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwriting the history file with the latest version\n",
    "# history_code.to_csv('../data/history_code.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8693c0a-22c6-4999-8202-68754010119d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the model to get initial feedback\n",
    "# response = openai.ChatCompletion.create(\n",
    "#   model=\"gpt-3.5-turbo\",\n",
    "#   messages=[\n",
    "#         {\"role\": \"system\", \"content\": \"You are reviewing code and giving recommendations on programming style\"},\n",
    "#         {\"role\": \"user\", \"content\": code_input},\n",
    "#     ]\n",
    "# )\n",
    "# feedback = response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98f282a6-c5b4-4183-9fa4-c1ca32acd693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17c05084-0ff1-4c99-a7e7-814150fb81d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace with PATH here\n",
    "# history_feedback = pd.read_csv('../data/history_feedback.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5d2a097-b7ac-458a-a95c-fda5a8b4876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latest_feedback = pd.DataFrame({\n",
    "#     'date':today,\n",
    "#     'code_input':feedback\n",
    "# }, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5e803b8-5757-4749-a029-5ab368642f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating the history file\n",
    "# history_feedback = pd.concat([history_feedback, latest_feedback], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f375afce-d40c-4023-b6eb-090da245e1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwriting the file\n",
    "# history_feedback.to_csv('../data/history_feedback.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6affaef-0216-47b9-b47b-af85334e5d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76330750-b652-4bb5-9b0e-01eebadaaf14",
   "metadata": {},
   "source": [
    "# Learning goals "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b536255f-8a9e-4a33-88c3-9d0180ee0c89",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Set learning goals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee840c2c-f8dd-45d5-b0b4-70a88930b96f",
   "metadata": {},
   "source": [
    "### Langchain implementation area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9cbd79ef-9256-4ba2-a5bc-d298ea5e8233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This has to be done once and then only if the user checks a button like \"generate learning targets\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a8cd72-57e2-445c-92ec-95c7e660f528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the last X feedbacks\n",
    "# append or concatenate the txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae6b1baa-f85c-4558-b7b1-3f4a3027bc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_short_feedbacks = str(\n",
    "    \"\\n\\nImprove programming style: Use docstrings, descriptive variable names, logical sections/functions, consistent formatting, linter/formatter, comments, remove unnecessary code, try-catch blocks, context managers.\\n\\n1. Move non-Streamlit code to separate file.\\n2. Move Streamlit styling code to separate file.\\n3. Use meaningful variable names.\\n4. Use descriptive function names.\\n5. Add comments to explain code.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e242032f-d779-4540-9c1c-b45e85f45385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nImprove programming style: Use docstrings, descriptive variable names, logical sections/functions, consistent formatting, linter/formatter, comments, remove unnecessary code, try-catch blocks, context managers.\\n\\n1. Move non-Streamlit code to separate file.\\n2. Move Streamlit styling code to separate file.\\n3. Use meaningful variable names.\\n4. Use descriptive function names.\\n5. Add comments to explain code.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_short_feedbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9bf72919-ff81-41a5-a2d4-3d65613df242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the prompt template for a standardized input\n",
    "learning_goal_prompt = PromptTemplate(\n",
    "    input_variables=[\"latest_short_feedbacks\"],\n",
    "    template=\"Please select the four most relevant points from this list of feedback comments. Consider content recommendations more relevant than format recommendations. Consider repetitive aspects more. List of feedback comments: {latest_short_feedbacks}.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f797f124-c69b-4abf-9d6a-e402f4fa2f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the LM\n",
    "# TODO: check for optimal LLM\n",
    "learning_goal_llm = OpenAI(temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8d4b4d1-d3f3-4c42-ac81-af8c35548b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple chain taking user input, formatting the prompt and sending it to the LM\n",
    "learning_goal_chain = LLMChain(llm=learning_goal_llm, prompt=learning_goal_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "163396a4-e25c-4383-880a-00378fa85760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the chain only specifying the input variable.\n",
    "learning_goals = learning_goal_chain.run(latest_short_feedbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dc3910a6-41b8-4aef-9431-5cc74f8c0195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n6. Use linter/formatter to maintain consistent formatting.\\n7. Use try-catch blocks to handle exceptions.\\n8. Use context managers to manage resources.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a39940-8cd0-4f93-8f5d-4ee77b7af758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61a15287-5ca2-4ffd-b0cb-c2d69fd469ac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Direct API + JSON area OLD"
   ]
  },
  {
   "cell_type": "raw",
   "id": "de53b857-a980-4dfa-9570-b8277ea6c9e0",
   "metadata": {},
   "source": [
    "# read history_short_feedback"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4a43c367-68d0-4e7c-aa1c-cd48fbed1f5e",
   "metadata": {},
   "source": [
    "history_short_feedback"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c256c12-6ad3-450b-aa87-ad504240b5c9",
   "metadata": {},
   "source": [
    "short_feedb_json = history_short_feedback['short_feedback'].to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "afbe2425-f2b7-4e7c-a9f3-6ea781438b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"0\":\"The feedback suggests that the code can be improved by: \\\\n1. using meaningful variable names, \\\\n2. modularizing the code, \\\\n3. using docstrings to describe functions, \\\\n4. avoiding hardcoding values, \\\\n5. adding error handling, \\\\n6. using consistent formatting, and \\\\n7. organizing imports.\"}'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_feedb_json"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9a4d02fd-99dd-40fa-b6e7-95da20f97397",
   "metadata": {},
   "source": [
    "# maybe add a rule like \"put special weight on recurring aspects\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "cffcd79b-548e-4820-92ea-ef8e65e8f439",
   "metadata": {},
   "source": [
    "# calling the model to get initial feedback\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Summarize the feedback and create up to 4 short learning targets. A learning target should be an aspect of coding the user can focus on and try to improve when coding\"},\n",
    "        {\"role\": \"user\", \"content\": short_feedb_json},\n",
    "    ]\n",
    ")\n",
    "learning_target = response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "55ee63e2-7487-4e79-b3a1-7e5a70cc12df",
   "metadata": {},
   "source": [
    "learning_target"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c1b42c3a-d7c9-4ee3-9c6d-bf5b16810f85",
   "metadata": {},
   "source": [
    "# write the string variable to a JSON file\n",
    "with open('../data/learning_target.json', 'w') as f:\n",
    "    json.dump(learning_target, f)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d971bec9-7d9c-47cb-80df-bfad94ac5e9b",
   "metadata": {},
   "source": [
    "# TODO: add option to generate new learning targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecbbaf3-c1e0-44de-a738-676f67687019",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compare learning goals and latest submitted code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96073c03-03b3-494e-a5ce-223809119ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1b84066-2ffe-4896-b7ad-a7ea96448932",
   "metadata": {},
   "source": [
    "### Langchain implementation area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be8f8d8-4a36-442b-8851-441f85e6028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read latest learning goals!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c81016c1-4655-4a91-bace-12831c6292d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_prompt = PromptTemplate(\n",
    "    input_variables=[\"code_input\", \"learning_goals\"],\n",
    "    template=\"Please compare this code: {code_input} with these learning goals: {learning_goals}. If the programmer considered the learning goals when writing the provided code, say something motivating. If the programmer didn't consider the learning goals, gently remind the person of their learning goals.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9c7d72b6-27ce-41c9-a25e-2c9f32af044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_prompt = evaluation_prompt.format(code_input=code_input, learning_goals=learning_goals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d1e1a411-2b19-4b4f-8f83-1c470b7da64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_llm = OpenAI(temperature=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c0b3cfa1-36a7-4096-884f-026cd0f1509a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nYes, the programmer appears to have considered the learning goals when writing the provided code. The code is well-formatted and easy to read, and the programmer has included try-catch blocks and context managers to handle exceptions and manage resources.'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_llm(evaluation_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e5d2e3-75aa-4b41-bac7-3d77219fa1b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5e9ed4-1082-4ff9-8c7f-aeb383104a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d911d08f-f605-4cc4-8eea-71d1b5796311",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Json + direct API area OLD"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7e2e0477-b91b-422a-ac00-3af19573a8cb",
   "metadata": {},
   "source": [
    "# read the JSON file\n",
    "with open('../data/learning_target.json', 'r') as f:\n",
    "    learning_target = json.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b6c88ecd-63d7-4026-8165-b24ee65a441d",
   "metadata": {},
   "source": [
    "learning_target"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cf036b10-47f5-4e1b-9c99-ebfdc4177f65",
   "metadata": {},
   "source": [
    "feedback"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4cdf34e3-dc35-4cfe-abce-b9c4c2c61ed4",
   "metadata": {},
   "source": [
    "# TODO: Improve system prompt!"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e42f277-ac7f-4699-98f5-fd3034cf7071",
   "metadata": {},
   "source": [
    "# calling the model to get initial feedback\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "        {\"role\": \"system\", \"content\": \"Compare the learning targets and the feedback. If there is a strong overlap between the latest feedback and the learning targets, the user didn't pay attention to the targets. If that is the case, give him a friendly reminder to pay attention to the learning targets.\"},\n",
    "        {\"role\": \"user\", \"content\": learning_target},\n",
    "        {\"role\": \"user\", \"content\": feedback}\n",
    "    ]\n",
    ")\n",
    "reminder = response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1d0cd6d9-3490-4911-89e6-eb380e6af34a",
   "metadata": {},
   "source": [
    "reminder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
